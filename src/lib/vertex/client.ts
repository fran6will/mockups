import { GoogleGenerativeAI } from '@google/generative-ai';

// Initialize the Google Gen AI Client
const apiKey = process.env.GEMINI_API_KEY;

// Using Copié-Collé (Gemini 3 Pro Image)
const modelId = 'gemini-3-pro-image-preview';

export const generateMockup = async (
    baseImageUrl: string,
    logoUrl: string,
    prompt: string,
    aspectRatio: string = '1:1',
    imageSize: string = '1K'
) => {
    if (!apiKey) {
        throw new Error("Missing GEMINI_API_KEY in environment variables.");
    }

    try {
        console.log(`Calling Copié-Collé (Gemini API) with Aspect Ratio: ${aspectRatio} and Size: ${imageSize}...`);

        const genAI = new GoogleGenerativeAI(apiKey);
        const model = genAI.getGenerativeModel({
            model: modelId,
            generationConfig: {
                // Gemini 3 Pro Image requires both TEXT and IMAGE modalities
                responseModalities: ["TEXT", "IMAGE"],
                imageConfig: {
                    aspectRatio: aspectRatio,
                    imageSize: imageSize
                }
            } as any
        });

        // Helper to fetch and convert URL to Base64
        const urlToPart = async (url: string) => {
            const response = await fetch(url);
            const arrayBuffer = await response.arrayBuffer();
            const base64 = Buffer.from(arrayBuffer).toString('base64');
            const mimeType = response.headers.get('content-type') || 'image/png';
            return {
                inlineData: {
                    data: base64,
                    mimeType
                }
            };
        };

        console.log("Fetching image assets...");
        const [baseImagePart, logoImagePart] = await Promise.all([
            urlToPart(baseImageUrl),
            urlToPart(logoUrl)
        ]);

        // 1. Prepare Inputs
        // The 'prompt' variable contains either the custom product instruction or a default instruction.
        const fullPrompt = `Generate a photorealistic product shot. ${prompt} Important: Keep the provided design/logo unchanged, preserving its colors, text, and details exactly as they appear. Apply it realistically to the surface. Ensure high quality, detailed texture, and realistic lighting.`;

        console.log("Sending request to model with images...");
        // 2. Call API
        // Pass the text prompt AND the image parts
        const result = await model.generateContent([
            fullPrompt,
            baseImagePart,
            logoImagePart
        ]);
        const response = await result.response;

        // 3. Extract Image
        // We'll inspect the response structure. 
        // If it's standard text generation, it returns text.
        // If it's image generation, it usually returns inlineData.

        console.log("Model response candidates:", response.candidates);

        const parts = response.candidates?.[0]?.content?.parts;
        const imagePart = parts?.find((part: any) => part.inlineData);

        if (!imagePart || !imagePart.inlineData) {
            // If no image part, maybe it returned text saying it can't do it?
            const textPart = parts?.find((part: any) => part.text);
            if (textPart) {
                console.warn("Model returned text instead of image:", textPart.text);
                throw new Error("Model returned text: " + textPart.text);
            }
            throw new Error("No image generated by the model.");
        }

        const base64Image = imagePart.inlineData.data;
        const mimeType = imagePart.inlineData.mimeType || 'image/png';

        return {
            success: true,
            mockUrl: `data:${mimeType};base64,${base64Image}`
        };

    } catch (error: any) {
        console.error("Gemini API Error:", error);
        return {
            success: false, // Let the frontend show the error
            error: error.message || "Unknown error"
        };
    }
};

export const analyzeMockupImage = async (imageUrl: string, productType: 'mockup' | 'scene' = 'mockup', productNameHint?: string, keywordsHint?: string) => {
    if (!apiKey) {
        throw new Error("Missing GEMINI_API_KEY in environment variables.");
    }

    try {
        const genAI = new GoogleGenerativeAI(apiKey);
        // Use Gemini 3 Pro Preview as requested
        const model = genAI.getGenerativeModel({ model: "gemini-3-pro-preview" });

        // Fetch image and convert to base64
        const response = await fetch(imageUrl);
        const arrayBuffer = await response.arrayBuffer();
        const base64 = Buffer.from(arrayBuffer).toString('base64');
        const mimeType = response.headers.get('content-type') || 'image/png';

        let prompt = '';

        const hintContext = productNameHint ? `Context/Product Name: "${productNameHint}".` : '';
        const keywordContext = keywordsHint ? `Keywords to include: "${keywordsHint}".` : '';

        if (productType === 'scene') {
            prompt = `
                Analyze this background scene image and generate SEO-optimized details for it.
                ${hintContext}
                ${keywordContext}
                Return ONLY a JSON object with the following fields:
                - title: A catchy, descriptive title (e.g., "Cozy Wooden Desk Scene with Coffee").
                - description: A detailed, SEO-friendly description highlighting the lighting, mood, and available space for product placement.
                - tags: A comma-separated string of 5-10 relevant keywords (e.g., "desk, wood, coffee, cozy, morning, workspace").
                - slug: A URL-friendly slug based on the title (e.g., "cozy-wooden-desk-scene").
                - custom_prompt: A short instruction for an AI to place a product into this scene (e.g., "Place the product on the center of the wooden desk, matching the warm morning lighting and soft shadows.").
                
                Do not include markdown formatting like \`\`\`json. Just the raw JSON string.
            `;
        } else {
            prompt = `
                Analyze this product mockup image and generate SEO-optimized details for it.
                ${hintContext}
                ${keywordContext}
                Return ONLY a JSON object with the following fields:
                - title: A catchy, descriptive title (e.g., "Minimalist White Hoodie Mockup on Hanger").
                - description: A detailed, SEO-friendly description highlighting the setting, lighting, and vibe.
                - tags: A comma-separated string of 5-10 relevant keywords (e.g., "hoodie, streetwear, hanger, white, minimalist").
                - slug: A URL-friendly slug based on the title (e.g., "minimalist-white-hoodie-hanger").
                - custom_prompt: A short instruction for an AI to place a design on this product (e.g., "Place the design on the center chest area, maintaining the fabric wrinkles and lighting.").
                
                Do not include markdown formatting like \`\`\`json. Just the raw JSON string.
            `;
        }

        const result = await model.generateContent([
            prompt,
            {
                inlineData: {
                    data: base64,
                    mimeType
                }
            }
        ]);

        const text = result.response.text();

        // Clean up markdown if present
        const cleanText = text.replace(/```json/g, '').replace(/```/g, '').trim();

        return JSON.parse(cleanText);

    } catch (error: any) {
        console.error("Gemini Analysis Error:", error);
        throw new Error("Failed to analyze image: " + error.message);
    }
};

export const generateScene = async (
    baseImageUrl: string,
    prompt: string,
    styleReferenceUrls: string[] = [],
    aspectRatio: string = '1:1'
) => {
    if (!apiKey) {
        throw new Error("Missing GEMINI_API_KEY in environment variables.");
    }

    try {
        console.log(`Calling Copié-Collé (Gemini Scene Generation) with ${styleReferenceUrls.length} style refs and ratio ${aspectRatio}...`);

        const genAI = new GoogleGenerativeAI(apiKey);
        const model = genAI.getGenerativeModel({
            model: modelId,
            generationConfig: {
                responseModalities: ["IMAGE"],
                imageConfig: {
                    aspectRatio: aspectRatio,
                    imageSize: "1K"
                }
            } as any
        });

        // Helper to fetch and convert URL to Base64 (reused from generateProductPlacement logic if needed, or defined here)
        const urlToPart = async (url: string) => {
            // Check if it's already a data URL
            if (url.startsWith('data:')) {
                const [mimeType, base64] = url.split(';base64,');
                return {
                    inlineData: {
                        data: base64,
                        mimeType: mimeType.replace('data:', '')
                    }
                };
            }
            const response = await fetch(url);
            const arrayBuffer = await response.arrayBuffer();
            const base64 = Buffer.from(arrayBuffer).toString('base64');
            const mimeType = response.headers.get('content-type') || 'image/png';
            return {
                inlineData: {
                    data: base64,
                    mimeType
                }
            };
        };

        const baseImagePart = await urlToPart(baseImageUrl);

        const styleParts = await Promise.all(
            styleReferenceUrls.map(url => urlToPart(url))
        );

        // Construct Prompt
        const fullPrompt = `
            Take this blank product image (first image) and place it into a professional, photorealistic scene.
            ${prompt}
            ${styleParts.length > 0 ? 'Use the provided additional images as STYLE REFERENCES for the lighting, mood, and composition.' : ''}
            Important: Keep the product itself (shape, material) exactly as is, just change the background and lighting to match the scene.
            Ensure high quality, detailed texture, and realistic lighting.
        `;

        console.log("Sending scene generation request...");
        const result = await model.generateContent([
            fullPrompt,
            baseImagePart,
            ...styleParts
        ]);
        const apiResponse = await result.response;

        const parts = apiResponse.candidates?.[0]?.content?.parts;
        const imagePart = parts?.find((part: any) => part.inlineData);

        if (!imagePart || !imagePart.inlineData) {
            throw new Error("No image generated by the model.");
        }

        const base64Image = imagePart.inlineData.data;
        const resMimeType = imagePart.inlineData.mimeType || 'image/png';

        return {
            success: true,
            mockUrl: `data:${resMimeType};base64,${base64Image}`
        };

    } catch (error: any) {
        console.error("Gemini Scene Gen Error:", error);
        return {
            success: false,
            error: error.message || "Unknown error"
        };
    }
};

export const generateProductPlacement = async (
    sceneImageUrl: string,
    mainProductImageUrl: string,
    referenceProductImageUrls: string[],
    prompt: string,
    aspectRatio: string = '1:1',
    imageSize: string = '1K'
) => {
    if (!apiKey) {
        throw new Error("Missing GEMINI_API_KEY in environment variables.");
    }

    try {
        console.log(`Calling Copié-Collé (Product Placement) with Aspect Ratio: ${aspectRatio} and Size: ${imageSize}...`);

        const genAI = new GoogleGenerativeAI(apiKey);
        const model = genAI.getGenerativeModel({
            model: modelId,
            generationConfig: {
                responseModalities: ["TEXT", "IMAGE"],
                imageConfig: {
                    aspectRatio: aspectRatio,
                    imageSize: imageSize
                }
            } as any
        });

        // Helper to fetch and convert URL to Base64
        const urlToPart = async (url: string) => {
            const response = await fetch(url);
            const arrayBuffer = await response.arrayBuffer();
            const base64 = Buffer.from(arrayBuffer).toString('base64');
            const mimeType = response.headers.get('content-type') || 'image/png';
            return {
                inlineData: {
                    data: base64,
                    mimeType
                }
            };
        };

        console.log("Fetching image assets...");

        // Fetch Scene and Main Product
        const [sceneImagePart, mainProductPart] = await Promise.all([
            urlToPart(sceneImageUrl),
            urlToPart(mainProductImageUrl)
        ]);

        // Fetch Reference Images
        const referenceParts = await Promise.all(
            referenceProductImageUrls.map(url => urlToPart(url))
        );

        // Construct Prompt for Product Placement
        const fullPrompt = `
            Generate a photorealistic product photography shot.
            ${prompt}
            Task: REPLACE the sample product in the provided scene (first image) with the new product provided (second image and references).
            CRITICAL INSTRUCTIONS:
            1. IDENTIFY the sample product/object currently in the scene (first image).
            2. REPLACE that object completely with the new product from the second image.
            3. MATCH the exact position, scale, perspective, and lighting of the original sample product.
            4. PRESERVE the new product's identity (shape, label, colors, details) exactly as shown in the reference images.
            5. The background scene must remain unchanged, only the product is swapped.
            6. Ensure realistic shadows and reflections that match the scene's lighting environment.
        `;

        console.log(`Sending request to model with ${referenceParts.length} reference images...`);

        const result = await model.generateContent([
            fullPrompt,
            sceneImagePart,
            mainProductPart,
            ...referenceParts
        ]);
        const response = await result.response;

        console.log("Model response candidates:", response.candidates);

        const parts = response.candidates?.[0]?.content?.parts;
        const imagePart = parts?.find((part: any) => part.inlineData);

        if (!imagePart || !imagePart.inlineData) {
            const textPart = parts?.find((part: any) => part.text);
            if (textPart) {
                console.warn("Model returned text instead of image:", textPart.text);
                throw new Error("Model returned text: " + textPart.text);
            }
            throw new Error("No image generated by the model.");
        }

        const base64Image = imagePart.inlineData.data;
        const mimeType = imagePart.inlineData.mimeType || 'image/png';

        return {
            success: true,
            mockUrl: `data:${mimeType};base64,${base64Image}`
        };

    } catch (error: any) {
        console.error("Gemini Product Placement Error:", error);
        return {
            success: false,
            error: error.message || "Unknown error"
        };
    }
};

export const refinePrompt = async (prompt: string) => {
    if (!apiKey) {
        throw new Error("Missing GEMINI_API_KEY in environment variables.");
    }

    try {
        const genAI = new GoogleGenerativeAI(apiKey);
        // Use a text-optimized model for this
        const model = genAI.getGenerativeModel({ model: "gemini-3-pro-preview" });

        const systemPrompt = `
            You are an expert photographer and prompt engineer for AI image generation.
            Your task is to take a simple user description and enhance it into a detailed, photorealistic scene description for product photography.
            
            Focus on:
            - Lighting (e.g., cinematic, soft, golden hour, studio)
            - Texture and Materials (e.g., marble, wood, fabric)
            - Mood and Atmosphere
            - Composition (e.g., depth of field, bokeh)
            
            Constraints:
            - Keep the product itself generic (refer to it as "the product") as it will be inserted later.
            - Keep the description under 50 words.
            - Return ONLY the enhanced prompt text. Do not add quotes or explanations.
            
            User Input: "${prompt}"
        `;

        const result = await model.generateContent(systemPrompt);
        const response = await result.response;
        return response.text().trim();

    } catch (error: any) {
        console.error("Gemini Prompt Refinement Error:", error);
        throw new Error("Failed to refine prompt: " + error.message);
    }
};
